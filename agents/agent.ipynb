{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "author: Martiño Ríos García\n",
    "date: 2024-05-17\n",
    "title: 9 | Agents\n",
    "keep-ipynb: True\n",
    "include-in-header:\n",
    "  text: |\n",
    "    <style>\n",
    "    .cell-output-stdout {\n",
    "      overflow-y: scroll;\n",
    "      max-height: 400px;\n",
    "    }\n",
    "    .cell-output-display {\n",
    "      overflow-y: scroll;\n",
    "      max-height: 400px;\n",
    "    }\n",
    "    </style>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has the objective to show how to build LLM agents and how they work. For this practical application we will focus on trying to extract chemical reactions from an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-caution title=\"Installing the packages needed\"}\n",
    "\n",
    "All the dependencies needed to run the Notebooks of the book can be installed by installing the general package. This Notebook it is an exception to that because we are going to use a package that need specific dependencies versions. Thus, to install the dependencies that are used in this Notebook, we recommend executing the next commands in your console: \n",
    "\n",
    "```\n",
    "conda create --name agent_notebook\n",
    "conda activate agent_notebook\n",
    "conda install python=3.8\n",
    "git clone https://github.com/thomas0809/RxnScribe.git\n",
    "cd RxnScribe\n",
    "pip install -e .\n",
    "cd -\n",
    "pip install torch PubChemPy rdkit-pypi jupyter matplotlib huggingface-hub python-dotenv litellm langchain langchainhub langchain-community langchain_openai openai\n",
    "```\n",
    "\n",
    "With this, you will be able to run the Notebook.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "import torch\n",
    "import pubchempy as pcp\n",
    "from rxnscribe import RxnScribe\n",
    "from rdkit import Chem  \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from huggingface_hub import hf_hub_download\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.agents.react.agent import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.column-margin}\n",
    "The *.env* needs to contain your personal OpenAI key if you want to run the exact same example as ours. We insist that using the environment variables is the safest way of keeping personal API keys secret.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this small demonstration we will use *OpenAI* newest model: *GPT-4o*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *GPT-4o* model by *OpenAI* as its predecessor, *GPT-4.5 Turbo*, are multimodal models meaning that they can work with multimodal inputs such as text and images. Despite this models work quite well for some tasks, they can not perform that well when the data is very field-specific. To demonstrate this, we are going to provide an image describing a chemical reaction asking the model to extract the information describing the reaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@article{Ogasawara2015,\n",
    "  title = {Enantioselective Synthesis of Planar-Chiral Ferrocene-Fused 4-Pyridones and Their Application in Construction of Pyridine-Based Organocatalyst Library},\n",
    "  volume = {17},\n",
    "  ISSN = {1523-7052},\n",
    "  url = {http://dx.doi.org/10.1021/acs.orglett.5b01044},\n",
    "  DOI = {10.1021/acs.orglett.5b01044},\n",
    "  number = {9},\n",
    "  journal = {Organic Letters},\n",
    "  publisher = {American Chemical Society (ACS)},\n",
    "  author = {Ogasawara,  Masamichi and Wada,  Shiro and Isshiki,  Erika and Kamimura,  Takumi and Yanagisawa,  Akira and Takahashi,  Tamotsu and Yoshida,  Kazuhiro},\n",
    "  year = {2015},\n",
    "  month = apr,\n",
    "  pages = {2286–2289}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the test, we are going to work with an image extracted from a work by Ogasawara et al.[@Ogasawara2015]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"image.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure taken from a published article by Ogasawara et al.[@Ogasawara2015] illustrating enantioselective addition of o-tBu-Phenol to Ethyl(p-tolyl)ketene catalyzed by (S)-1 where S](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the record we know:\n",
    "Compound number 12: p-tolyl(ethyl)ketene -> systematic name: 2-(4-Methylphenyl)-1-buten-1-one -> SMILES: CCC(=C=O)c1ccc(cc1)C -> InChI: InChI=1S/C11H12O/c1-3-10(8-12)11-6-4-9(2)5-7-11/h4-7H,3H2,1-2H3\n",
    "\n",
    "Compound number 13: 2-(tert-Butyl)phenol -> systematic name: 2-(2-Methyl-2-propanyl)phenol -> SMILES: CC(C)(C)c1ccccc1O -> InChI: InChI=1S/C10H14O/c1-10(2,3)8-6-4-5-7-9(8)11/h4-7,11H,1-3H3\n",
    "\n",
    "Compound number 14: 2-(2-methyl-2-propanyl)phenyl (2S)-2-(4-methylphenyl)butanoate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pass the image to the model through the prompt, the image needs to be encoded. To do that we use the function that [*OpenAI* propose in their vision guidelines](https://platform.openai.com/docs/guides/vision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "      \n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we generate the prompt using the function just defined to encode the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a chemistry expert assistant, and your task is to extract information about chemical reactions from images.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Please extract all the information from the next image containing a chemical reaction. For the reactants that you find, give the name or some molecular representation, such as SMILES.\"},\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we do the completion using the *OpenAI* API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion(\n",
    "  model=model,\n",
    "  messages=messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.column-margin}\n",
    "Using `LiteLLM` when doing the completion allow using almost any model. In this demo, we used *OpenAI* model because this provider models together with *Claude* vision models are the ones that showed the best results overall.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image shows a chemical reaction involving the following reactants and conditions:\\n\\nReactants:\\n1. Compound 12:\\n   - Name: 1-phenyl-2-propyn-1-one\\n   - Molecular representation (SMILES): CC(=O)C#Cc1ccccc1\\n\\n2. Compound 13:\\n   - Name: 4-tert-butylphenol\\n   - Molecular representation (SMILES): CC(C)(C)c1ccc(CC(O)c2ccccc2)cc1\\n\\nReaction Conditions:\\n- Catalyst: (S)-1 (used in 3 mol%)\\n- Solvent: Toluene\\n- Temperature: 23°C\\n- Time: 2 hours\\n\\nProduct:\\n- (R)-14:\\n  - Name: (R)-2-hydroxy-1-phenyl-1-(4-(tert-butyl)phenoxy)-propan-1-one\\n  - Molecular representation (SMILES): CC(C)(C)c1ccc(O[C@@H](C(=O)c2ccccc2)C)c2ccccc2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to see that the model can not give the proper name or molecular representation to the molecules. Studying molecule by molecule, for the compound 12 both the name and the SMILES are wrong, and point to different molecules. Impressively, the name for the compound 13 is almost correct. The 4-tert-Butylphenol compound is a positional isomer of the actual compound, the 2-tert-Butylphenol. However, the SMILES is incorrect and does not even correspond to the 4-tert-Butylphenol molecule. As for the products, note that in the query we explicitly ask only about the reactants, so the model can not even reason about what we are asking.\n",
    "\n",
    "But luckily, some tools were developed to extract accurately this information from the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of these tools is *RxnScribe* developed by Qian et al.[@RxnScribe]. This tool can extract chemical reactions from images. So, we will use it as a tool given to an agent that we create bellow. With this and other tools, we will try that the model can extract information such as the IUPAC name and the InChI representation for the reactants involved in the reaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@article{RxnScribe,\n",
    "    author = {Qian, Yujie and Guo, Jiang and Tu, Zhengkai and Coley, Connor W. and Barzilay, Regina},\n",
    "    title = {RxnScribe: A Sequence Generation Model for Reaction Diagram Parsing},\n",
    "    journal = {Journal of Chemical Information and Modeling},\n",
    "    doi = {10.1021/acs.jcim.3c00439}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to describe the input to the tool\n",
    "class ExtractionInput(BaseModel):\n",
    "    image_path: str = Field(description=\"Path to the image-file that contain the reaction\")\n",
    "\n",
    "# Define the function that will do the reaction extraction.\n",
    "def extractor(image_path:str) -> list:\n",
    "    ckpt_path = hf_hub_download(\"yujieq/RxnScribe\", \"pix2seq_reaction_full.ckpt\")\n",
    "    model = RxnScribe(ckpt_path, device=torch.device(\"cuda\"))\n",
    "    results = model.predict_image_file(image_file, molscribe=True, ocr=True)\n",
    "\n",
    "    # Clean the output to reduce the number of tokens\n",
    "    for result in results:\n",
    "        for key, value in result.items():\n",
    "            for v in value:\n",
    "                if 'molfile' in v:\n",
    "                    v.pop('molfile')\n",
    "    return results\n",
    "                \n",
    "# Describe the tool for the model\n",
    "image_extractor = StructuredTool.from_function(\n",
    "    func=extractor,\n",
    "    name=\"Reaction extractor\",\n",
    "    description=\"Extract chemical reactions information such as reactants, products and catalysts from images\",\n",
    "    args_schema=ExtractionInput,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.column-margin}\n",
    "To create the model we use the *LangChain* package that allows to create an agent in a few lines of code. However, this is done because it better fits in the purpose of this Notebook. But we point as in the article, that building an agent without these frameworks such as LangChain and LlamaIndex is feasible and will offer more clarity and flexibility to the process.\n",
    ":::\n",
    "::: {.column-margin}\n",
    "Note that before returning the output from the RxnScribe tool, we \"pop\" some elements from it. This is simply because those elements are quite big, and since we are not going to need them, we will save some tokens.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print the variable containing the tool, we will be able to see what is going to be passed to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction extractor\n",
      "Extract chemical reactions information such as reactants, products and catalysts from images\n",
      "{'image_path': {'title': 'Image Path', 'description': 'Path to the image-file that contain the reaction', 'type': 'string'}}\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(image_extractor.name)\n",
    "print(image_extractor.description)\n",
    "print(image_extractor.args)\n",
    "print(image_extractor.return_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we can define another tools for helping the agent to go from SMILES to InChI and to IUPAC name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChemicalTools(BaseModel):\n",
    "    smiles: str = Field(description=\"SMILES representation for the molecule\")\n",
    "\n",
    "def smiles_to_inchi(smiles:str) -> str:\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "    return Chem.MolToInchi(molecule)\n",
    "\n",
    "CACTUS = \"https://cactus.nci.nih.gov/chemical/structure/{0}/{1}\"\n",
    "\n",
    "def smiles_to_iupac(smiles:str) -> str:\n",
    "    \"\"\"\n",
    "    Use the chemical name resolver https://cactus.nci.nih.gov/chemical/structure. \n",
    "    If this does not work, use pubchem.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        time.sleep(0.001)\n",
    "        rep = \"iupac_name\"\n",
    "        url = CACTUS.format(smiles, rep)\n",
    "        response = requests.get(url, allow_redirects=True, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        name = response.text\n",
    "        if \"html\" in name:\n",
    "            return None\n",
    "        return name\n",
    "    except Exception:\n",
    "        try:\n",
    "            compound = pcp.get_compounds(smiles, \"smiles\")\n",
    "            return compound[0].iupac_name\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "smiles_to_inchi_converter = StructuredTool.from_function(\n",
    "    func=smiles_to_inchi,\n",
    "    name=\"Smiles to InChI\",\n",
    "    description=\"Return the inchi representation of the given smiles representation\",\n",
    "    args_schema=ChemicalTools,\n",
    ")\n",
    "\n",
    "smiles_to_iupac_converter = StructuredTool.from_function(\n",
    "    func=smiles_to_iupac,\n",
    "    name=\"Smiles to IUPAC\",\n",
    "    description=\"Return the iupac name of the given smiles representation\",\n",
    "    args_schema=ChemicalTools,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we defined all the tools, we create a list that is going to be passed to the agent indicating which tools it has available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [image_extractor, smiles_to_inchi_converter, smiles_to_iupac_converter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating and defining the tools, we can start to construct the agent itself starting by defining the model to use. For the agent we will use the *GPT-4o* model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-4o\",\n",
    "    request_timeout=1000,\n",
    "    streaming='False',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the prompt, the agent and what it is called by *LangChain* as the \"*chain*\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-tip title=\"ReAct prompt used\" collapse=\"true\"}\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ReAct prompt from the hub.\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "# Construct the ReAct agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "# Define the chain for the agent.\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, \n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step before calling the agent is to define the query that we want the agent to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"I want the IUPAC name, the SMILES and the InChI representations for the reactants of the reaction contained in the image: {image_file}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we run the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer this question, I need to extract the chemical reactions information from the image first. This will give me the reactants, products, and catalysts involved in the reaction. Then, I can convert the SMILES representations of the reactants to their IUPAC names and InChI representations.\n",
      "\n",
      "Action: Reaction extractor\n",
      "Action Input: image.png\u001b[0m\u001b[36;1m\u001b[1;3m[{'reactants': [{'category': '[Mol]', 'bbox': (0.057028514257128564, 0.007119217971975312, 0.28414207103551775, 0.733279451113457), 'category_id': 1, 'smiles': 'CCC(=C=O)c1ccc(C)cc1'}, {'category': '[Mol]', 'bbox': (0.32066033016508255, 0.042715307831851866, 0.4687343671835918, 0.7261602331414817), 'category_id': 1, 'smiles': 'CC(C)Cc1ccccc1O'}], 'conditions': [{'category': '[Txt]', 'bbox': (0.4867433716858429, 0.07356525237707821, 0.6008004002001001, 0.35121475328411533), 'category_id': 2, 'text': ['(S)-1', '(3 mol %-']}, {'category': '[Txt]', 'bbox': (0.4842421210605303, 0.38681084314399194, 0.6018009004502252, 0.6549680534217287), 'category_id': 2, 'text': ['toluene', '23 %C, 2 h']}], 'products': [{'category': '[Mol]', 'bbox': (0.6223111555777889, 0.04983452580382718, 0.9459729864932466, 0.733279451113457), 'category_id': 1, 'smiles': '[H][C@](CC)(C(=O)Oc1ccccc1CC(C)C)c1ccc(C)cc1'}]}]\u001b[0m\u001b[32;1m\u001b[1;3mThe reaction extractor has provided the SMILES representations of the reactants. The next step is to convert these SMILES strings to their IUPAC names and InChI representations.\n",
      "\n",
      "The reactants are:\n",
      "1. SMILES: `CCC(=C=O)c1ccc(C)cc1`\n",
      "2. SMILES: `CC(C)Cc1ccccc1O`\n",
      "\n",
      "I will first convert the SMILES to IUPAC names.\n",
      "\n",
      "Action: Smiles to IUPAC\n",
      "Action Input: CCC(=C=O)c1ccc(C)cc1\u001b[0m\u001b[38;5;200m\u001b[1;3mNone\u001b[0m\u001b[32;1m\u001b[1;3mIt seems there was an issue with the observation. I will try converting the SMILES to IUPAC names again.\n",
      "\n",
      "Action: Smiles to IUPAC\n",
      "Action Input: CCC(=C=O)c1ccc(C)cc1\u001b[0m\u001b[38;5;200m\u001b[1;3mNone\u001b[0m\u001b[32;1m\u001b[1;3mIt appears that there might be an issue with the tool for converting SMILES to IUPAC names. I will attempt to convert the second SMILES string to its IUPAC name to see if the issue persists.\n",
      "\n",
      "Action: Smiles to IUPAC\n",
      "Action Input: CC(C)Cc1ccccc1O\u001b[0m\u001b[38;5;200m\u001b[1;3m2-(2-Methylpropyl)phenol\u001b[0m\u001b[32;1m\u001b[1;3mIt seems that the tool successfully converted the second SMILES string to its IUPAC name, but there was an issue with the first SMILES string. I will now proceed to convert the SMILES strings to their InChI representations.\n",
      "\n",
      "Action: Smiles to InChI\n",
      "Action Input: CCC(=C=O)c1ccc(C)cc1\u001b[0m\u001b[33;1m\u001b[1;3mInChI=1S/C11H12O/c1-3-10(8-12)11-6-4-9(2)5-7-11/h4-7H,3H2,1-2H3\u001b[0m\u001b[32;1m\u001b[1;3mThe InChI representation for the first reactant has been successfully obtained. I will now convert the second SMILES string to its InChI representation.\n",
      "\n",
      "Action: Smiles to InChI\n",
      "Action Input: CC(C)Cc1ccccc1O\u001b[0m\u001b[33;1m\u001b[1;3mInChI=1S/C10H14O/c1-8(2)7-9-5-3-4-6-10(9)11/h3-6,8,11H,7H2,1-2H3\u001b[0m\u001b[32;1m\u001b[1;3mThe InChI representation for the second reactant has been successfully obtained. I now have the necessary information to provide the final answer.\n",
      "\n",
      "Final Answer:\n",
      "1. Reactant 1:\n",
      "   - SMILES: `CCC(=C=O)c1ccc(C)cc1`\n",
      "   - IUPAC Name: (Unable to retrieve)\n",
      "   - InChI: `InChI=1S/C11H12O/c1-3-10(8-12)11-6-4-9(2)5-7-11/h4-7H,3H2,1-2H3`\n",
      "\n",
      "2. Reactant 2:\n",
      "   - SMILES: `CC(C)Cc1ccccc1O`\n",
      "   - IUPAC Name: 2-(2-Methylpropyl)phenol\n",
      "   - InChI: `InChI=1S/C10H14O/c1-8(2)7-9-5-3-4-6-10(9)11/h3-6,8,11H,7H2,1-2H3`\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I want the IUPAC name, the SMILES and the InChI representations for the reactants of the reaction contained in the image: image.png',\n",
       " 'output': '1. Reactant 1:\\n   - SMILES: `CCC(=C=O)c1ccc(C)cc1`\\n   - IUPAC Name: (Unable to retrieve)\\n   - InChI: `InChI=1S/C11H12O/c1-3-10(8-12)11-6-4-9(2)5-7-11/h4-7H,3H2,1-2H3`\\n\\n2. Reactant 2:\\n   - SMILES: `CC(C)Cc1ccccc1O`\\n   - IUPAC Name: 2-(2-Methylpropyl)phenol\\n   - InChI: `InChI=1S/C10H14O/c1-8(2)7-9-5-3-4-6-10(9)11/h3-6,8,11H,7H2,1-2H3`'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to observe that the agent reason correctly to first use the tool to extract the information from the image, and then it converts the SMILES into InChI representations and IUPAC names."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
